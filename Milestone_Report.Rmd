---
title: "Milestone Report for NLP Capstone Project"
subtitle: "Data Science Specialization on Coursera"
author: "Vadim K."
date: "22 August 2017"
output: 
    html_document:
        keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Synopsis

The purpose of this document is to provide a milestone report on developing an 
interactive text prediction web app.  
This developement is a part of capstone project that 
wraps up Coursera Data Science specialization offered by Johns Hopkins University (Baltimore, Maryland).

This application will predict the next word a user most likely will type 
based on the words he/she already typed.  
The server part of application will run a word prediction algorithm that will be finalized later in the project. 
This algorithm is based on N-gram language model built from [HC Corpora](https://web-beta.archive.org/web/20160930083655/http://www.corpora.heliohost.org/aboutcorpus.html) (a set of files with millions lines of text in different languages collected from publicly available sources by a web crawler).

In the present document I will give a brief overview of the first steps of the project 
that were already achieved such as downloading, cleaning and exploring the data. 
I will also share couple of issues I faced and some interesting findings in the data.  
In conclusion you'll find some info about my plans for creating the prediction algorithm and the expected constraints.


## Data Processing
библиотеки


### _Loading Data_

описываем что была проблема из-за символов
_Issue found (and solved) on loading_
решаем и грузим


### _Summary statistics_
графики с общим количеством строк, символов, размером файлов

### Sampling Data
делаем сэмпл

### _Cleaning Data_
_Issue found (and solved) on samples_
описываем и чистим
сохраняем сэмплы для дальнейшего использования

## Exploring the Data

чтобы продолжить разобьем на предложения
и потом токены (в целях exploring уберем stop words и сделаем стеммы, потом для
предсказания не будем)
и потом dfm
и потом частоты

графики

## Plans for Prediction Algorithm
сам алгоритм построим на n-gram language model
будем использовать 1-4-граммы и smooting (поэкспериментируем с Good-Turing and 
Katz's back-of)
ограничения:  

* размеры итоговых таблиц (будем использовать data.table, как советуют fellow data scientists on course forum), 
* оперативка на Shiny Server (1 RAM), для экспериментов может сделаем вирт.машину с подобными параметрами

